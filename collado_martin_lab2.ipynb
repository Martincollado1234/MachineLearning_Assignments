{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kuzushiji Classification with Support Vector Machines\n",
    "\n",
    "In this notebook we are going to explore the use of Support Vector Machines (SVM) for image classification. We will use a variant of the famous MNIST dataset (the original is a dataset of handwritten digits). The version we are going to use is called Kuzushiji-MNIST or K-MNIST for short (https://github.com/rois-codh/kmnist) and is a dataset of traditional japanese handwritten kana.\n",
    "\n",
    "\n",
    "\n",
    "The dataset labels are the following:\n",
    "\n",
    "| Label | Hiragana Character | Romanji (Pronunciation) |\n",
    "| :-: | :-: | :-: |\n",
    "|   0   | お | o |\n",
    "| 1 | き | ki |\n",
    "| 2 | す | su |\n",
    "| 3 | つ | tsu |\n",
    "| 4 | な | na |\n",
    "| 5 | は | ha |\n",
    "| 6 | ま | ma |\n",
    "| 7 | や | ya |\n",
    "| 8 | れ | re |\n",
    "| 9 | を | wo |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Insert your surname, name and ID number\n",
    "\n",
    "Student surname: Collado\n",
    "\n",
    "Student name: Martin\n",
    "    \n",
    "ID: 2039907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas \n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load Kuzushiji-MNIST dataset\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    labels_path = os.path.join(path, 'K%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, 'K%s-images-idx3-ubyte.gz' % kind)\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels), 784)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix your ID (\"numero di matricola\") and the seed for random generator (as usual you can try different seeds)\n",
    "ID = 2039907\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "#load the K-MNIST dataset from the 'data' folder and let's normalize the features so that each value is in [0,1] \n",
    "\n",
    "X, y = load_mnist('data', kind='train')\n",
    "# rescale the data\n",
    "X, y = X / 255., y # original pixel values are between 0 and 255\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into training and test. Make sure that each label is present at least 10 times\n",
    "in training. If it is not, then keep adding permutations to the initial data until this \n",
    "happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [62 62 61 69 50 59 56 62 65 54]\n"
     ]
    }
   ],
   "source": [
    "# Random permute the data and split into training and test taking the first 600\n",
    "# data samples as training and 4000 samples as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 600\n",
    "m_test = 4000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:m_training+m_test:]\n",
    "y_train, y_test = y[:m_training], y[m_training:m_training+m_test:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %i\"%labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQ/UlEQVR4nO3de2xVZboG8OelXJQ7pVhJQcsZUY9BBCx44YSgwljxD5gET6gJ4SgKJpoMhhgJxkBMNEaFYWLqhTmW6cAomThDIBEFUzA6/iGUOz3gKSowYG1LuLTjDdu+549ucjrY9a7t3mvvtbvf55eQtvvp1/1lw8Pa3d9e6xNVBRHlv15xT4CIsoNlJ3KCZSdygmUncoJlJ3KidzbvrKioSEtLS7N5l0SuHD9+HGfOnJHusrTKLiLlAH4PoADAf6vqi9b3l5aWora2Np27JCJDWVlZYJby03gRKQBQCeA+ADcBqBCRm1L9eUSUWen8zj4FwDFV/VJVLwLYCGB2NNMioqilU/YSAP/o8vWpxG3/QkQWiUitiNQ2NzencXdElI50yt7diwA/e++tqq5V1TJVLRsxYkQad0dE6Uin7KcAjO7y9SgAX6c3HSLKlHTKvhvAWBEZIyJ9AcwDsCWaaRFR1FJeelPVNhF5AsA2dC69ValqXWQzyyOzZ9uvWw4aNMjMN2zYEOV0yKm01tlVdSuArRHNhYgyiG+XJXKCZSdygmUncoJlJ3KCZSdygmUnciKr57Pnq++++87Md+zYYeYzZ86McjpE3eKRncgJlp3ICZadyAmWncgJlp3ICZadyAkuvUXg9OnTZt7W1mbmvIIPZQOP7EROsOxETrDsRE6w7EROsOxETrDsRE6w7EROcJ09AuvXrzfzH374wczDdrYNW6fv3Zt/jRSOR3YiJ1h2IidYdiInWHYiJ1h2IidYdiInWHYiJ7hAG4H+/fubeXl5uZmHraP36pWf/ydfuHDBzKurq8184cKFZt6nT5/ArG/fvubYfJRW2UXkOIBWAO0A2lS1LIpJEVH0ojiy36WqZyL4OUSUQfn5/JCIfibdsiuA7SKyR0QWdfcNIrJIRGpFpLa5uTnNuyOiVKVb9qmqOgnAfQAeF5Fpl3+Dqq5V1TJVLeOFFYnik1bZVfXrxMcmAJsATIliUkQUvZTLLiIDRGTQpc8B/BrA4agmRkTRSufV+GIAm0Tk0s95W1U/iGRWGdDe3m7mBQUFKf/sJUuWmPldd91l5i+99FLK9x23sHP1KysrA7O5c+eaY0ePHm3mFRUVZn7w4MHArKqqyhx79913m3lPlHLZVfVLALdEOBciyiAuvRE5wbITOcGyEznBshM5wbITOZE3p7iGLQEtXrw4rfzOO+8MzOrq6syxYUtEt9xiL2p0dHSYeSZPgT1x4kRa9z1//vzArKioyBx77bXXmnlhYaGZz5w5MzBbunSpOXb37t1m3hMv380jO5ETLDuREyw7kRMsO5ETLDuREyw7kRMsO5ETPW+xMEDYpYGfe+45M7/66qtTvu93333XzL/66iszHzJkiJmns2Vz2PsPzpyxrxX65ptvmvmTTz5p5pm8OpH13gcAKC0tDcwOHDhgjg1770TYeyNyEY/sRE6w7EROsOxETrDsRE6w7EROsOxETrDsRE7kzTp72HnVYedGp+Phhx8285KSEjPfu3evmZ8/f97Mjx07Fpht3brVHHvrrbea+QsvvGDmcbK2ZAaA559/PjB75JFHzLHpvO8iV/HITuQEy07kBMtO5ATLTuQEy07kBMtO5ATLTuRE3qyzZ5q1/W91dbU5dvny5WYeds36xsZGM29ubg7MrGunA8C0adPMvCfbuHFjYNbS0mKO/fzzz828uLg4pTnFKfTILiJVItIkIoe73FYoIh+KSH3i47DMTpOI0pXM0/g/Aii/7LZlAGpUdSyAmsTXRJTDQsuuqh8DOHvZzbMBXHruWg1gTsTzIqKIpfoCXbGqNgBA4uNVQd8oIotEpFZEaq3fLYkoszL+aryqrlXVMlUty+TFB4nIlmrZG0VkJAAkPjZFNyUiyoRUy74FwILE5wsAbI5mOkSUKaHr7CLyDoDpAIpE5BSAFQBeBPAXEVkI4CSABzI5yVxQU1MTmL322mvm2F27dpn5008/beabN9v/lw4YMCAwW7VqlTm2oKDAzHuyBx98MDALu1b/4MGDo55O7ELLrqoVAdE9Ec+FiDKIb5clcoJlJ3KCZSdygmUncoJlJ3KCp7gmad68eYFZ2Gmk+/btM/PTp0+b+Zo1a8zcWnrz7O233w7MVNUc2xO3ZA7DIzuREyw7kRMsO5ETLDuREyw7kRMsO5ETLDuRE27W2X/66Scz37Ztm5nPmDEjMBs5cqQ5Nmz737DTKfv27Wvm1L1z584FZmFXTero6DDznnhqMI/sRE6w7EROsOxETrDsRE6w7EROsOxETrDsRE7kzTp7a2urma9fvz6t3Nqid/z48ebYoqIiM6fMKC+/fD/S//f666+bY9vb282c6+xElLNYdiInWHYiJ1h2IidYdiInWHYiJ1h2Iid61Dq7df31b775xhx7//33m/k999ib0n766aeBWT5eY7wn+P777828oaEhMJs4caI5tnfvHlWNpIQe2UWkSkSaRORwl9tWishpEdmf+DMrs9MkonQl8zT+jwC6eyvS71R1QuLP1minRURRCy27qn4M4GwW5kJEGZTOC3RPiMjBxNP8YUHfJCKLRKRWRGqbm5vTuDsiSkeqZX8dwK8ATADQAGBV0Deq6lpVLVPVsrCL/BFR5qRUdlVtVNV2Ve0A8AcAU6KdFhFFLaWyi0jXayf/BsDhoO8lotwQupgoIu8AmA6gSEROAVgBYLqITACgAI4DWBzFZE6ePGnm69atC8zC1tFHjRpl5p988omZW+uyLS0t5thXXnnFzFeuXGnmV1xxhZl7VVdXZ+Y1NTWB2YoVK8yxvXrl3/vNQsuuqhXd3PxWBuZCRBmUf/99EVG3WHYiJ1h2IidYdiInWHYiJ7J6Hl9rayt27twZmG/fvt0cP3z48MBs165d5tgbbrjBzKdOnWrm1pbPYadazp0718zPnz9v5tZlrAFARMw8X+3YscPMDx06FJh5vLw3j+xETrDsRE6w7EROsOxETrDsRE6w7EROsOxETmR1nb1Xr1648sorA/NXX33VHD927NjAbOjQoebYsLXuPn36mPmJEycCs6NHj5pjrfcWAMC4cePM/KGHHjLzfPXtt9+aeWVlpZnffPPNgVlJSUlKc+rJeGQncoJlJ3KCZSdygmUncoJlJ3KCZSdygmUnciKr6+z9+/fHpEmTAvM9e/aY463L++7du9cca63RJ+Oaa64JzPbv32+ODbuMtfXeA88OH7a3I2hsbDTzp556KjC77rrrUppTT8YjO5ETLDuREyw7kRMsO5ETLDuREyw7kRMsO5ETWV1nv3jxorkt82OPPWaOv/feewOzZcuWpTyvZFjXZrfmBQDvv/++mYeN92rChAlmvmHDBjO/4447Ur7vjo4OMw/bXry0tNTMVTUwy9Q+AKFHdhEZLSI7ReSIiNSJyG8TtxeKyIciUp/4OCwjMySiSCTzNL4NwFJV/XcAtwN4XERuArAMQI2qjgVQk/iaiHJUaNlVtUFV9yY+bwVwBEAJgNkAqhPfVg1gTqYmSUTp+0Uv0IlIKYCJAD4DUKyqDUDnfwgArgoYs0hEakWk9uzZs+nNlohSlnTZRWQggL8CWKKqLcmOU9W1qlqmqmWFhYWpzJGIIpBU2UWkDzqL/mdV/Vvi5kYRGZnIRwJoyswUiSgKoUtv0rkO8BaAI6q6uku0BcACAC8mPm4O+1n9+vXDmDFjAvOqqipz/KBBg8LuImPOnDkTmNXX15tjV69ebeaTJ0828yFDhph5vurXr5+Zz5ljv0x07ty5wCzs72zTpk1mXlFRYeZhP3/btm2BmXU6NQDMmjUrMLOW9JJZZ58KYD6AQyJy6cTt5egs+V9EZCGAkwAeSOJnEVFMQsuuqn8HELTKf0+00yGiTOHbZYmcYNmJnGDZiZxg2YmcYNmJnMjqKa4AUFBQEJhZa/Bxs9YvX375ZXPsvn37zPzHH39MaU7e9e5t//O1LjX97LPPmmPXrFlj5iNGjDDzCxcumPn06dMDs2eeecYca51e29zcHJjxyE7kBMtO5ATLTuQEy07kBMtO5ATLTuQEy07kRNbX2XuqL774IjA7cOCAOTbsvOzi4uKU5kS266+/PjALWwffvXu3mZeXl5t52OWgP/vss8Ds0UcfNcfOmDEjMFu3bl1gxiM7kRMsO5ETLDuREyw7kRMsO5ETLDuREyw7kRNcZ09Se3t7YDZu3Dhz7MCBA8188ODBKc3Ju7a2NjN/7733ArOPPvrIHBt2DYIPPvjAzG+77TYzX7hwoZmnylrf55GdyAmWncgJlp3ICZadyAmWncgJlp3ICZadyIlk9mcfDeBPAK4G0AFgrar+XkRWAngUwKULVS9X1a2Zmmjcjh49GpiF7RP+wAP2btbWtfTzWUNDg5mHXbt9586dZn777bcHZlu32v9UJ0+ebObDhw8381yUzJtq2gAsVdW9IjIIwB4R+TCR/U5VX8nc9IgoKsnsz94AoCHxeauIHAFQkumJEVG0ftHv7CJSCmAigEvX1HlCRA6KSJWIDAsYs0hEakWk1tqahogyK+myi8hAAH8FsERVWwC8DuBXACag88i/qrtxqrpWVctUtSxsfywiypykyi4ifdBZ9D+r6t8AQFUbVbVdVTsA/AHAlMxNk4jSFVp26TyN5i0AR1R1dZfbR3b5tt8AOBz99IgoKsm8Gj8VwHwAh0Rkf+K25QAqRGQCAAVwHMDijMwwR5SVlQVmLS0t5tihQ4dGPZ2cYZ36CwD19fWB2RtvvGGObWpqMvPKykozHz9+fGAWdnnvfJTMq/F/B9DdSbJ5u6ZOlI/4DjoiJ1h2IidYdiInWHYiJ1h2IidYdiIneCnpJFnr7J6FnZ574403BmZhp7BStHhkJ3KCZSdygmUncoJlJ3KCZSdygmUncoJlJ3JCVDV7dybSDOBEl5uKAJzJ2gR+mVydW67OC+DcUhXl3K5V1W6v/5bVsv/szkVqVTUn362Sq3PL1XkBnFuqsjU3Po0ncoJlJ3Ii7rKvjfn+Lbk6t1ydF8C5pSorc4v1d3Yiyp64j+xElCUsO5ETsZRdRMpF5HMROSYiy+KYQxAROS4ih0Rkv4jUxjyXKhFpEpHDXW4rFJEPRaQ+8bHbPfZimttKETmdeOz2i8ismOY2WkR2isgREakTkd8mbo/1sTPmlZXHLeu/s4tIAYD/BTATwCkAuwFUqOr/ZHUiAUTkOIAyVY39DRgiMg3APwH8SVXHJW57CcBZVX0x8R/lMFV9OkfmthLAP+PexjuxW9HIrtuMA5gD4L8Q42NnzOs/kYXHLY4j+xQAx1T1S1W9CGAjgNkxzCPnqerHAM5edvNsANWJz6vR+Y8l6wLmlhNUtUFV9yY+bwVwaZvxWB87Y15ZEUfZSwD8o8vXp5Bb+70rgO0iskdEFsU9mW4Uq2oD0PmPB8BVMc/ncqHbeGfTZduM58xjl8r25+mKo+zdbSWVS+t/U1V1EoD7ADyeeLpKyUlqG+9s6Wab8ZyQ6vbn6Yqj7KcAjO7y9SgAX8cwj26p6teJj00ANiH3tqJuvLSDbuKjvfthFuXSNt7dbTOOHHjs4tz+PI6y7wYwVkTGiEhfAPMAbIlhHj8jIgMSL5xARAYA+DVybyvqLQAWJD5fAGBzjHP5F7myjXfQNuOI+bGLfftzVc36HwCz0PmK/BcAnoljDgHz+jcABxJ/6uKeG4B30Pm07id0PiNaCGA4gBoA9YmPhTk0t/UADgE4iM5ijYxpbv+Bzl8NDwLYn/gzK+7HzphXVh43vl2WyAm+g47ICZadyAmWncgJlp3ICZadyAmWncgJlp3Iif8DASYBfQQaoAAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 8\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 0\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 5\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 4\n"
     ]
    }
   ],
   "source": [
    "#let's try the plotting function\n",
    "plot_input(X_train,y_train,5)\n",
    "plot_input(X_test,y_test,50)\n",
    "plot_input(X_test,y_test,500)\n",
    "plot_input(X_test,y_test,700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "Use a SVM classifier with cross validation to pick a model. Use a 4-fold cross-validation. Let's start with a Linear kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrador\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found: {'C': 0.1, 'kernel': 'linear'}\n",
      "Score with best parameters: 0.75\n",
      "Results for Linear Kernel:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.288494</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>0.076040</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>0.01</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.01, 'kernel': 'linear'}</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.047823</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.222914</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.057586</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.782895</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.218167</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.055850</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>0.038139</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.217898</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.055630</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>0.038139</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.288494      0.007344         0.076040        0.007136    0.01   \n",
       "1       0.222914      0.001118         0.057586        0.002391     0.1   \n",
       "2       0.218167      0.004425         0.055850        0.001222       1   \n",
       "3       0.217898      0.003627         0.055630        0.001463      10   \n",
       "\n",
       "  param_kernel                           params  split0_test_score  \\\n",
       "0       linear  {'C': 0.01, 'kernel': 'linear'}           0.683871   \n",
       "1       linear   {'C': 0.1, 'kernel': 'linear'}           0.709677   \n",
       "2       linear     {'C': 1, 'kernel': 'linear'}           0.709677   \n",
       "3       linear    {'C': 10, 'kernel': 'linear'}           0.709677   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0           0.776316           0.802721           0.712329         0.743333   \n",
       "1           0.782895           0.795918           0.712329         0.750000   \n",
       "2           0.776316           0.795918           0.712329         0.748333   \n",
       "3           0.776316           0.795918           0.712329         0.748333   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.047823                4  \n",
       "1        0.039447                1  \n",
       "2        0.038139                2  \n",
       "3        0.038139                2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import SVC\n",
    "from sklearn.svm import SVC\n",
    "#import for Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {'C': [0.01, 0.1, 1, 10],\n",
    "              'kernel': ['linear'] \n",
    "             }\n",
    "\n",
    "#train linear SVM\n",
    "gridsearchcv = GridSearchCV(SVC(),parameters,cv=4)\n",
    "gridsearchcv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_parameter = gridsearchcv.best_params_\n",
    "print(\"Best parameters set found:\",best_parameter)\n",
    "\n",
    "best_score = gridsearchcv.best_score_\n",
    "print(\"Score with best parameters:\",best_score)\n",
    "\n",
    "print(\"Results for Linear Kernel:\")\n",
    "results = gridsearchcv.cv_results_\n",
    "dfresults = pd.DataFrame(results)\n",
    "dfresults\n",
    "#dfresults[['params','split0_test_score','split1_test_score','split2_test_score','split3_test_score','mean_test_score','rank_test_score']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 2\n",
    "Pick a model for the Polynomial kernel with degree=2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrador\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR POLY DEGREE=2 KERNEL\n",
      "Best parameters set found: {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "Score with best parameters: 0.7533333333333333\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.342557</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>0.064345</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01, 'kernel': 'poly'}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.260074</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>0.057576</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.036604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.277042</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.055080</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.01, 'gamma': 1, 'kernel': 'poly'}</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.743421</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.324133</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>0.064330</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'}</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.462585</td>\n",
       "      <td>0.431507</td>\n",
       "      <td>0.438333</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.280970</td>\n",
       "      <td>0.014966</td>\n",
       "      <td>0.054863</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}</td>\n",
       "      <td>0.754839</td>\n",
       "      <td>0.743421</td>\n",
       "      <td>0.789116</td>\n",
       "      <td>0.691781</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.034520</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.279018</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.054839</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1, 'kernel': 'poly'}</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.743421</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.256571</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.057598</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01, 'kernel': 'poly'}</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.036604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.276527</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.054847</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'poly'}</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.743421</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.335746</td>\n",
       "      <td>0.046164</td>\n",
       "      <td>0.066447</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'poly'}</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.743421</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.342557      0.004481         0.064345        0.001107    0.01   \n",
       "1       0.260074      0.009696         0.057576        0.001272    0.01   \n",
       "2       0.277042      0.006264         0.055080        0.001604    0.01   \n",
       "3       0.324133      0.004857         0.064330        0.002294     0.1   \n",
       "4       0.280970      0.014966         0.054863        0.000708     0.1   \n",
       "5       0.279018      0.003540         0.054839        0.001217     0.1   \n",
       "6       0.256571      0.009108         0.057598        0.000837       1   \n",
       "7       0.276527      0.006288         0.054847        0.000991       1   \n",
       "8       0.335746      0.046164         0.066447        0.006121       1   \n",
       "\n",
       "  param_gamma param_kernel                                        params  \\\n",
       "0        0.01         poly  {'C': 0.01, 'gamma': 0.01, 'kernel': 'poly'}   \n",
       "1         0.1         poly   {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}   \n",
       "2           1         poly     {'C': 0.01, 'gamma': 1, 'kernel': 'poly'}   \n",
       "3        0.01         poly   {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'}   \n",
       "4         0.1         poly    {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}   \n",
       "5           1         poly      {'C': 0.1, 'gamma': 1, 'kernel': 'poly'}   \n",
       "6        0.01         poly     {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}   \n",
       "7         0.1         poly      {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}   \n",
       "8           1         poly        {'C': 1, 'gamma': 1, 'kernel': 'poly'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.116129           0.111842           0.115646           0.116438   \n",
       "1           0.741935           0.776316           0.795918           0.698630   \n",
       "2           0.741935           0.743421           0.755102           0.705479   \n",
       "3           0.464516           0.394737           0.462585           0.431507   \n",
       "4           0.754839           0.743421           0.789116           0.691781   \n",
       "5           0.741935           0.743421           0.755102           0.705479   \n",
       "6           0.741935           0.776316           0.795918           0.698630   \n",
       "7           0.741935           0.743421           0.755102           0.705479   \n",
       "8           0.741935           0.743421           0.755102           0.705479   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.115000        0.001860                9  \n",
       "1         0.753333        0.036604                1  \n",
       "2         0.736667        0.018403                4  \n",
       "3         0.438333        0.028531                8  \n",
       "4         0.745000        0.034520                3  \n",
       "5         0.736667        0.018403                4  \n",
       "6         0.753333        0.036604                1  \n",
       "7         0.736667        0.018403                4  \n",
       "8         0.736667        0.018403                4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters for poly with degree 2 kernel\n",
    "parameters = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1,1],'kernel':['poly']}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "gridsearchcv = GridSearchCV(SVC(degree=2),parameters,cv=4)\n",
    "gridsearchcv.fit(X_train, y_train)\n",
    "\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=2 KERNEL')\n",
    "\n",
    "best_parameter = gridsearchcv.best_params_\n",
    "print(\"Best parameters set found:\",best_parameter)\n",
    "\n",
    "best_score = gridsearchcv.best_score_\n",
    "print(\"Score with best parameters:\",best_score)\n",
    "\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "results = gridsearchcv.cv_results_\n",
    "dfresults = pd.DataFrame(results)\n",
    "dfresults\n",
    "#dfresults[['params','split0_test_score','split1_test_score','split2_test_score','split3_test_score','mean_test_score','rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 3\n",
    "\n",
    "Now let's try a higher degree for the polynomial kernel (e.g., 3rd degree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrador\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR POLY DEGREE= 3  KERNEL\n",
      "Best parameters set found: {'C': 1, 'gamma': 0.01}\n",
      "Score with best parameters: 0.775\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.359295</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.066315</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.358057</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>0.065054</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.359047</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.065049</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 1}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.350327</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.065063</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01}</td>\n",
       "      <td>0.187097</td>\n",
       "      <td>0.217105</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.239726</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.021306</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.360063</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.065316</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.363264</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.067318</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.328393</td>\n",
       "      <td>0.007206</td>\n",
       "      <td>0.063819</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.754839</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.760274</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.021219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.362315</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.064802</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.135484</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.149660</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.138333</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.373166</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.069813</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'gamma': 1}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.359295      0.010920         0.066315        0.001679    0.01   \n",
       "1       0.358057      0.006317         0.065054        0.001293    0.01   \n",
       "2       0.359047      0.004953         0.065049        0.000816    0.01   \n",
       "3       0.350327      0.006029         0.065063        0.000837     0.1   \n",
       "4       0.360063      0.006755         0.065316        0.001136     0.1   \n",
       "5       0.363264      0.007794         0.067318        0.003345     0.1   \n",
       "6       0.328393      0.007206         0.063819        0.000987       1   \n",
       "7       0.362315      0.006963         0.064802        0.000954       1   \n",
       "8       0.373166      0.010468         0.069813        0.003069       1   \n",
       "\n",
       "  param_gamma                      params  split0_test_score  \\\n",
       "0        0.01  {'C': 0.01, 'gamma': 0.01}           0.116129   \n",
       "1         0.1   {'C': 0.01, 'gamma': 0.1}           0.116129   \n",
       "2           1     {'C': 0.01, 'gamma': 1}           0.116129   \n",
       "3        0.01   {'C': 0.1, 'gamma': 0.01}           0.187097   \n",
       "4         0.1    {'C': 0.1, 'gamma': 0.1}           0.116129   \n",
       "5           1      {'C': 0.1, 'gamma': 1}           0.116129   \n",
       "6        0.01     {'C': 1, 'gamma': 0.01}           0.754839   \n",
       "7         0.1      {'C': 1, 'gamma': 0.1}           0.135484   \n",
       "8           1        {'C': 1, 'gamma': 1}           0.116129   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0           0.111842           0.115646           0.116438         0.115000   \n",
       "1           0.111842           0.115646           0.116438         0.115000   \n",
       "2           0.111842           0.115646           0.116438         0.115000   \n",
       "3           0.217105           0.190476           0.239726         0.208333   \n",
       "4           0.111842           0.115646           0.116438         0.115000   \n",
       "5           0.111842           0.115646           0.116438         0.115000   \n",
       "6           0.776316           0.809524           0.760274         0.775000   \n",
       "7           0.131579           0.149660           0.136986         0.138333   \n",
       "8           0.111842           0.115646           0.116438         0.115000   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.001860                4  \n",
       "1        0.001860                4  \n",
       "2        0.001860                4  \n",
       "3        0.021306                2  \n",
       "4        0.001860                4  \n",
       "5        0.001860                4  \n",
       "6        0.021219                1  \n",
       "7        0.006747                3  \n",
       "8        0.001860                4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters for poly with higher degree kernel\n",
    "parameters = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1,1]}\n",
    "\n",
    "#run SVM with poly of higher degree kernel\n",
    "degree = 3\n",
    "gridsearchcv = GridSearchCV(SVC(degree),parameters,cv=4)\n",
    "gridsearchcv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=', degree, ' KERNEL')\n",
    "\n",
    "best_parameter = gridsearchcv.best_params_\n",
    "print(\"Best parameters set found:\",best_parameter)\n",
    "\n",
    "\n",
    "best_score = gridsearchcv.best_score_\n",
    "print(\"Score with best parameters:\",best_score)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "results = gridsearchcv.cv_results_\n",
    "dfresults = pd.DataFrame(results)\n",
    "dfresults\n",
    "#dfresults[['params','split0_test_score','split1_test_score','split2_test_score','split3_test_score','mean_test_score','rank_test_score']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 4\n",
    "Pick a model for the Radial Basis Function kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrador\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR rbf KERNEL\n",
      "Best parameters set found: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Score with best parameters: 0.8016666666666666\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.403181</td>\n",
       "      <td>0.042716</td>\n",
       "      <td>0.074807</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.349554</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.066582</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>0.187097</td>\n",
       "      <td>0.217105</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.239726</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.021306</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.358775</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.065324</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.360511</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>0.065334</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.311630</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>0.065362</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.721088</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.042628</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.328401</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.063571</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>0.754839</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.760274</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.021219</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.364535</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.065564</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.135484</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.149660</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.138333</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.363548</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>0.065804</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.228401</td>\n",
       "      <td>0.012209</td>\n",
       "      <td>0.061087</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>0.719178</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>0.051694</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.421103</td>\n",
       "      <td>0.045135</td>\n",
       "      <td>0.075325</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.782895</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.031080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.365007</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.065315</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.167742</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.176871</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.362555</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.065061</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.247595</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.062815</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.763333</td>\n",
       "      <td>0.033434</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.341300</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.062620</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.782895</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.031080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.366530</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.065082</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.167742</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.176871</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.362012</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.065078</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.403181      0.042716         0.074807        0.010986     0.1   \n",
       "1        0.349554      0.005308         0.066582        0.002141     0.1   \n",
       "2        0.358775      0.005224         0.065324        0.001131     0.1   \n",
       "3        0.360511      0.005018         0.065334        0.001487     0.1   \n",
       "4        0.311630      0.008927         0.065362        0.001107       1   \n",
       "5        0.328401      0.007162         0.063571        0.000836       1   \n",
       "6        0.364535      0.008048         0.065564        0.000812       1   \n",
       "7        0.363548      0.007734         0.065804        0.001216       1   \n",
       "8        0.228401      0.012209         0.061087        0.002271      10   \n",
       "9        0.421103      0.045135         0.075325        0.006844      10   \n",
       "10       0.365007      0.008517         0.065315        0.001120      10   \n",
       "11       0.362555      0.006249         0.065061        0.001098      10   \n",
       "12       0.247595      0.008667         0.062815        0.006738     100   \n",
       "13       0.341300      0.005415         0.062620        0.000847     100   \n",
       "14       0.366530      0.001812         0.065082        0.000816     100   \n",
       "15       0.362012      0.006575         0.065078        0.001278     100   \n",
       "\n",
       "   param_gamma param_kernel                                       params  \\\n",
       "0        0.001          rbf  {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "1         0.01          rbf   {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "2          0.1          rbf    {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "3            1          rbf      {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "4        0.001          rbf    {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "5         0.01          rbf     {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "6          0.1          rbf      {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "7            1          rbf        {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "8        0.001          rbf   {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "9         0.01          rbf    {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "10         0.1          rbf     {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "11           1          rbf       {'C': 10, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "12       0.001          rbf  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "13        0.01          rbf   {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "14         0.1          rbf    {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "15           1          rbf      {'C': 100, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.116129           0.111842           0.115646   \n",
       "1            0.187097           0.217105           0.190476   \n",
       "2            0.116129           0.111842           0.115646   \n",
       "3            0.116129           0.111842           0.115646   \n",
       "4            0.658065           0.684211           0.721088   \n",
       "5            0.754839           0.776316           0.809524   \n",
       "6            0.135484           0.131579           0.149660   \n",
       "7            0.116129           0.111842           0.115646   \n",
       "8            0.703226           0.802632           0.823129   \n",
       "9            0.806452           0.782895           0.850340   \n",
       "10           0.167742           0.157895           0.176871   \n",
       "11           0.116129           0.111842           0.115646   \n",
       "12           0.722581           0.789474           0.802721   \n",
       "13           0.806452           0.782895           0.850340   \n",
       "14           0.167742           0.157895           0.176871   \n",
       "15           0.116129           0.111842           0.115646   \n",
       "\n",
       "    split3_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.116438         0.115000        0.001860               11  \n",
       "1            0.239726         0.208333        0.021306                7  \n",
       "2            0.116438         0.115000        0.001860               11  \n",
       "3            0.116438         0.115000        0.001860               11  \n",
       "4            0.602740         0.666667        0.042628                6  \n",
       "5            0.760274         0.775000        0.021219                3  \n",
       "6            0.136986         0.138333        0.006747               10  \n",
       "7            0.116438         0.115000        0.001860               11  \n",
       "8            0.719178         0.761667        0.051694                5  \n",
       "9            0.767123         0.801667        0.031080                1  \n",
       "10           0.178082         0.170000        0.008118                8  \n",
       "11           0.116438         0.115000        0.001860               11  \n",
       "12           0.739726         0.763333        0.033434                4  \n",
       "13           0.767123         0.801667        0.031080                1  \n",
       "14           0.178082         0.170000        0.008118                8  \n",
       "15           0.116438         0.115000        0.001860               11  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters for rbf SVM\n",
    "parameters = {'C': [0.1, 1, 10, 100],'gamma':[0.001, 0.01, 0.1,1],'kernel': ['rbf'] }\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "gridsearchcv = GridSearchCV(SVC(),parameters,cv=4)\n",
    "gridsearchcv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print ('RESULTS FOR rbf KERNEL')\n",
    "\n",
    "best_parameter = gridsearchcv.best_params_\n",
    "print(\"Best parameters set found:\",best_parameter)\n",
    "\n",
    "best_score = gridsearchcv.best_score_\n",
    "print(\"Score with best parameters:\",best_score)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "results = gridsearchcv.cv_results_\n",
    "dfresults = pd.DataFrame(results)\n",
    "dfresults\n",
    "#dfresults[['params','split0_test_score','split1_test_score','split2_test_score','split3_test_score','mean_test_score','rank_test_score']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 1\n",
    "What do you observe when using linear, polynomial and RBF kernels on this dataset ?\n",
    "\n",
    "There are 2 parameters that we need to talk about.\n",
    "\n",
    "C parameter adds a penalty for each misclassified data point and controls the number of error in the training data. If C is low, SVM uses a limit boundary with a large margin, so it will contain more misclassifed samples, but if C is big, SVM will find a limit boundary with less margin and less misclassified samples.\n",
    "Gamma parameter controls the distance of influence of a single training point. If gamma is big this distance is very small, so point whic are really close can be classified as different, On the other hand a low gamma makes this distance bigger, so points that are close will be classified as the same group.\n",
    "\n",
    "Using a higher C and a higher gamma makes your model less generalized, getting really good results in training data but it might suffer from overfitting, getting bad results over the test data.\n",
    "\n",
    "In the lineal kernel, the best score is obtained with C=0.1.\n",
    "In the polinomial kernel degree 2 the best score is obtained with C=0.01 and gamma=0.1\n",
    "In the polinomial kernel degree 3 the best score is obtained with C=1 and gamma=0.001\n",
    "In the RBF kernel, the best score is obtained with C=10 and gamma=0.01\n",
    "\n",
    "What we can conclude about these results is that this dataset is not linearly separable. That's why when we use non linear kernels kernels the accuracy gets bettet than using linear kernel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 5\n",
    "Report here the best SVM kernel and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.000000\n",
      "Best SVM test error: 0.188750\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "\n",
    "best_SVM = SVC(C=10,kernel='rbf',gamma=0.01)\n",
    "\n",
    "best_SVM.fit(X_train,y_train)\n",
    "training_error = 1 - best_SVM.score(X_train,y_train)\n",
    "test_error = 1 - best_SVM.score(X_test,y_test)\n",
    "    \n",
    "# (error is 1 - svm.score)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 6\n",
    "\n",
    "Analyze how the gamma parameter (inversely proportional to standard deviation of Gaussian Kernel) impact the performances of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]\n"
     ]
    }
   ],
   "source": [
    "#Test with different values of gamma\n",
    "\n",
    "# Set gamma values\n",
    "gamma_values = np.logspace(-5,2,8)\n",
    "print(gamma_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy with different gammas [0.115, 0.7583333333333333, 0.9633333333333334, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "test accuracy with different gammas [0.099, 0.6925, 0.77275, 0.81125, 0.14575, 0.099, 0.099, 0.099]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try the SVM with the previously set values of gamma\n",
    "# use rbf kernel and C=1\n",
    "\n",
    "train_acc_list, test_acc_list = [], []\n",
    "\n",
    "for i in gamma_values:\n",
    "    svm = SVC(C=10,kernel='rbf',gamma=i)\n",
    "    svm.fit(X_train,y_train)\n",
    "    train_acc_list.append(svm.score(X_train,y_train))\n",
    "    test_acc_list.append(svm.score(X_test,y_test))\n",
    "print('training accuracy with different gammas',train_acc_list)\n",
    "print('test accuracy with different gammas',test_acc_list)\n",
    "\n",
    "    \n",
    "# ADD YOUR CODE TO TRAIN THE SVM MULTIPLE TIMES WITH THE DIFFERENT VALUES OF GAMMA\n",
    "# PLACE THE TRAIN AND TEST ACCURACY FOR EACH TEST IN THE TRAIN AND TEST ACCURACY LISTS\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "ax[0].plot(gamma_values, train_acc_list)\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('gamma')\n",
    "ax[0].set_ylabel('Train accuracy')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(gamma_values, test_acc_list)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('gamma')\n",
    "ax[1].set_ylabel('Test accuracy')\n",
    "ax[1].grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 2\n",
    "How do the train and test error change when changing gamma ? Which is the best value of gamma ? \n",
    "Connect your answers to the discussion about the overfitting issue.\n",
    "\n",
    "As I said before, gamma parameter controls the distance of influence of a single training point. If gamma is big this distance is very small, so points which are really close can be classified as different. On the other hand, a low gamma makes this distance bigger, so points that are close might be classified as the same group.\n",
    "\n",
    "Having a big gamma means that your classification boundary is closer to the training points, so in the training set, increasing gamma means having less errors in the training set. Even so, when gamma is 0.01 the accuracy stops getting better.\n",
    "On the other hand, in the test set, when we increase gamma, the model accuracy improves until  gamma is equal to 0.01  when the accuracy start getting worse because of overfitting. \n",
    "\n",
    "The best gamma is 0.01 because using it, we obtained the best training_accuracy and the best test_accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n",
    "Now let's do the same but using more data points for training.\n",
    "\n",
    "\n",
    "Choose a new number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [198 182 193 199 203 192 221 198 210 204]\n"
     ]
    }
   ],
   "source": [
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 2000 # TODO number of data points, adjust depending on the capabilities of your PC\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 7\n",
    "\n",
    "Let's try to use SVM with parameters obtained from the best model for $m_{training} =  2000$. Since it may take a long time to run, you can decide to just let it run for some time and stop it if it does not complete. If you decide to do this, report it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.000000\n",
      "Best SVM test error: 0.113690\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "\n",
    "\n",
    "best_SVM = SVC(C=10,kernel='rbf',gamma=0.01)\n",
    "best_SVM.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1 - best_SVM.score(X_train,y_train)\n",
    "test_error = 1 - best_SVM.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for comparison, let's also use logistic regression \n",
    "\n",
    "## TO DO 8 Try first without regularization (use a very large large C)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrador\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Administrador\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression training error: 0.000000\n",
      "Best logistic regression test error: 0.299586\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logisticregression=linear_model.LogisticRegression(C=1000)\n",
    "logisticregression.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1 - logisticregression.score(X_train,y_train)\n",
    "test_error = 1 - logisticregression.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 9 Try  with regularization (use C=1)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrador\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Administrador\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularized logistic regression training error: 0.013500\n",
      "Best regularized logistic regression test error: 0.254931\n"
     ]
    }
   ],
   "source": [
    "# ADD YOUR CODE\n",
    "logisticregression=linear_model.LogisticRegression(C=1)\n",
    "logisticregression.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1 - logisticregression.score(X_train,y_train)\n",
    "test_error = 1 - logisticregression.score(X_test,y_test)\n",
    "\n",
    "print (\"Best regularized logistic regression training error: %f\" % training_error)\n",
    "print (\"Best regularized logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 3\n",
    "Compare and discuss:\n",
    "- the results from SVM with m=600 and with m=2000 training data points. If you stopped the SVM, include such aspect in your comparison.\n",
    "- the results of SVM and of Logistic Regression\n",
    "\n",
    "When we use 2000 data points for training isntead of 600, the accuracy of the model increases. This is because the model has more info related to the data that it has to classify.\n",
    "\n",
    "The performance  of SVM is better than Logistic Regression. In case of the Logistic Regression, when we use regularization, the test error decreases because if it's used, it will prevent overfitting. A bigger C implies to be closer to overfitting.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 10\n",
    "Plot an item of clothing that is missclassified by logistic regression and correctly classified by SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y predicted by logistic regression wrong: 6\n",
      "Y predicted by svm correctly: 1\n",
      "real y: 1\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 1\n"
     ]
    }
   ],
   "source": [
    "LR_prediction = logisticregression.predict(X_test)\n",
    "SVM_prediction = best_SVM.predict(X_test)\n",
    "\n",
    "\n",
    "predicted_value=0\n",
    "index=0\n",
    "\n",
    "for i in y_test:\n",
    "    if ((LR_prediction[i]!=y_test[i]) and (SVM_prediction[i]==y_test[i])):\n",
    "        y_lr_predicted = LR_prediction[i]\n",
    "        y_svm_precited = SVM_prediction[i]\n",
    "        real_y = y_test[i]\n",
    "        index=i\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Y predicted by logistic regression wrong:\", y_lr_predicted)\n",
    "print(\"Y predicted by svm correctly:\", y_svm_precited)\n",
    "print(\"real y:\", real_y)\n",
    "\n",
    "plot_input(X_test,y_test,index)\n",
    "    \n",
    "    \n",
    "\n",
    "# ADD CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 11\n",
    "Plot the confusion matrix for the SVM classifier and for logistic regression.\n",
    "The confusion matrix has one column for each predicted label and one row for each true label. \n",
    "It shows for each class in the corresponding row how many samples belonging to that class gets each possible output label.\n",
    "Notice that the diagonal contains the correctly classified samples, while the other cells correspond to errors.\n",
    "You can obtain it with the sklearn.metrics.confusion_matrix function (see the documentation).\n",
    "Try also to normalize the confusion matrix by the number of samples in each class in order to measure the accuracy on each single class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and frequencies in test set:  [5802 5818 5807 5801 5797 5808 5779 5802 5790 5796]\n",
      "Labels and frequencies in training set:  [198 182 193 199 203 192 221 198 210 204]\n",
      "\n",
      " Confusion matrix SVM  \n",
      " \n",
      " [[5517    3    5   20   76   40    8   69   36   28]\n",
      " [  35 5038   85   71  136    4  190    6  111  142]\n",
      " [   1  115 4650  123   81   23  454   29  222  109]\n",
      " [  14   76   89 5416   52   38   26   31   36   23]\n",
      " [ 193  132  105   51 5007    9  107   38   87   68]\n",
      " [  69   68  211  193   69 4970   51   24  137   16]\n",
      " [  13  101  169   35  176    3 5162   74   39    7]\n",
      " [  59   21   62   74  156   21   51 5249   65   44]\n",
      " [  48  136   60   87   16   22  168    6 5228   19]\n",
      " [  34  178  138   19  122    5   25   38   68 5169]]\n",
      "\n",
      " Confusion matrix SVM (normalized)   \n",
      " \n",
      " [[0.95 0.   0.   0.   0.01 0.01 0.   0.01 0.01 0.  ]\n",
      " [0.01 0.87 0.01 0.01 0.02 0.   0.03 0.   0.02 0.02]\n",
      " [0.   0.02 0.8  0.02 0.01 0.   0.08 0.   0.04 0.02]\n",
      " [0.   0.01 0.02 0.93 0.01 0.01 0.   0.01 0.01 0.  ]\n",
      " [0.03 0.02 0.02 0.01 0.86 0.   0.02 0.01 0.02 0.01]\n",
      " [0.01 0.01 0.04 0.03 0.01 0.86 0.01 0.   0.02 0.  ]\n",
      " [0.   0.02 0.03 0.01 0.03 0.   0.89 0.01 0.01 0.  ]\n",
      " [0.01 0.   0.01 0.01 0.03 0.   0.01 0.9  0.01 0.01]\n",
      " [0.01 0.02 0.01 0.02 0.   0.   0.03 0.   0.9  0.  ]\n",
      " [0.01 0.03 0.02 0.   0.02 0.   0.   0.01 0.01 0.89]]\n",
      "\n",
      " Confusion matrix LR  \n",
      " \n",
      " [[4982    9   21   41  155  146   12  237   67  132]\n",
      " [  19 4053  423  118  241   67  319   61  249  268]\n",
      " [  10  272 3409  276  198   88  791   93  432  238]\n",
      " [  34  143  117 4541  218  280   76  124  187   81]\n",
      " [ 268  200  278   99 4184   49  210  177  114  218]\n",
      " [  80  131  309  267  111 4512   96   79  164   59]\n",
      " [  36  226  381  115  241   45 4333  165  203   34]\n",
      " [ 107   36  159  121  206   84  128 4693   98  170]\n",
      " [  89  349  281  151   51  126  328   45 4293   77]\n",
      " [ 168  280  370   46  263   38   89  176  152 4214]]\n",
      "\n",
      " Confusion matrix LR (normalized)   \n",
      " \n",
      " [[0.86 0.   0.   0.01 0.03 0.03 0.   0.04 0.01 0.02]\n",
      " [0.   0.7  0.07 0.02 0.04 0.01 0.05 0.01 0.04 0.05]\n",
      " [0.   0.05 0.59 0.05 0.03 0.02 0.14 0.02 0.07 0.04]\n",
      " [0.01 0.02 0.02 0.78 0.04 0.05 0.01 0.02 0.03 0.01]\n",
      " [0.05 0.03 0.05 0.02 0.72 0.01 0.04 0.03 0.02 0.04]\n",
      " [0.01 0.02 0.05 0.05 0.02 0.78 0.02 0.01 0.03 0.01]\n",
      " [0.01 0.04 0.07 0.02 0.04 0.01 0.75 0.03 0.04 0.01]\n",
      " [0.02 0.01 0.03 0.02 0.04 0.01 0.02 0.81 0.02 0.03]\n",
      " [0.02 0.06 0.05 0.03 0.01 0.02 0.06 0.01 0.74 0.01]\n",
      " [0.03 0.05 0.06 0.01 0.05 0.01 0.02 0.03 0.03 0.73]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(precision=2, suppress=True) # for better aligned printing of confusion matrix use floatmode='fixed'\n",
    "\n",
    "u, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Labels and frequencies in test set: \", counts)\n",
    "train, train_counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels and frequencies in training set: \", train_counts)\n",
    "\n",
    "confusion_SVM = confusion_matrix(y_test,SVM_prediction)\n",
    "print(\"\\n Confusion matrix SVM  \\n \\n\", confusion_SVM)\n",
    "print(\"\\n Confusion matrix SVM (normalized)   \\n \\n\", confusion_SVM /counts[:,None] )\n",
    "\n",
    "confusion_LR = confusion_matrix(y_test,LR_prediction)\n",
    "print(\"\\n Confusion matrix LR  \\n \\n\", confusion_LR)\n",
    "print(\"\\n Confusion matrix LR (normalized)   \\n \\n\", confusion_LR /counts[:,None] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4\n",
    "Have a look at the confusion matrices and comment on the obtained accuracies. Why some classes have lower accuracies and others an higher one ? Make some guesses on the possible causes.\n",
    "\n",
    "The classes that have more accuracy are less similar to the others than the ones that have less accuracy.\n",
    "For example, data belonging to class 2 (accuracy 0.8) are similar to data of class 6, we can see that observing Hiragana characters of it and analysing that in the confusion matrix when class 2 data is predicted wrongly, the prediction that occurs the most is data of class 6.\n",
    "Other example will be data belonging to class 5 (accuracy 0.86), when they are predicted errornously, most are predicted as samples of class 2. Again, if we look these Hiragana characters, they are similar too.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
